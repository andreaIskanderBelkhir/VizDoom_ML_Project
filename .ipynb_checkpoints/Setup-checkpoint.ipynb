{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cee3a09",
   "metadata": {},
   "source": [
    "# setup Vizdoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce3ed8e6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vizdoom\n",
      "  Downloading vizdoom-1.1.13-cp38-cp38-win_amd64.whl (15.4 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\andre\\anaconda3\\lib\\site-packages (from vizdoom) (1.20.1)\n",
      "Installing collected packages: vizdoom\n",
      "Successfully installed vizdoom-1.1.13\n"
     ]
    }
   ],
   "source": [
    "!pip install vizdoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "945c6707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import vizdoom for game env\n",
    "from vizdoom import * \n",
    "# Import random for action sampling\n",
    "import random\n",
    "# Import time for sleeping\n",
    "import time \n",
    "# Import numpy for identity matrix(action have only 3 value)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7dc960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup game\n",
    "game = DoomGame()\n",
    "game.load_config('github/VizDoom/scenarios/basic.cfg')\n",
    "game.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf149b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the set of actions we can take in the environment\n",
    "actions = np.identity(3, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d27cc1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: -4.0\n",
      "reward: 99.0\n",
      "Result: 95.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "Result: -385.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: 99.0\n",
      "Result: 91.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: 99.0\n",
      "Result: 83.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -9.0\n",
      "Result: -380.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: 99.0\n",
      "Result: 91.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: -4.0\n",
      "reward: 99.0\n",
      "Result: 87.0\n",
      "reward: -4.0\n",
      "reward: 99.0\n",
      "Result: 95.0\n",
      "reward: -4.0\n",
      "reward: 99.0\n",
      "Result: 95.0\n",
      "reward: -4.0\n",
      "reward: 99.0\n",
      "Result: 95.0\n"
     ]
    }
   ],
   "source": [
    "# Loop through episodes \n",
    "episodes = 10 \n",
    "for episode in range(episodes): \n",
    "    # Create a new episode or game \n",
    "    game.new_episode()\n",
    "    # Check the game isn't done \n",
    "    while not game.is_episode_finished(): \n",
    "        # Get the game state \n",
    "        state = game.get_state()\n",
    "        # Get the game image \n",
    "        img = state.screen_buffer\n",
    "        # Get the game variables - ammo\n",
    "        info = state.game_variables\n",
    "        # Take an action and skip 4 frame\n",
    "        reward = game.make_action(random.choice(actions),4)\n",
    "        # Print rewward \n",
    "        print('reward:', reward) \n",
    "        time.sleep(0.02)\n",
    "    print('Result:', game.get_total_reward())\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204f8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "game.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acebef6b",
   "metadata": {},
   "source": [
    "# Setup the gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71d6c145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\andre\\anaconda3\\lib\\site-packages (0.24.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from gym) (1.6.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from gym) (0.0.6)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from gym) (1.20.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from gym) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gym) (3.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01114d3a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-win_amd64.whl (35.6 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.1)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.6.0.66\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62bd9637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import env base\n",
    "from gym import Env\n",
    "#import gym space\n",
    "from gym.spaces import Discrete,Box\n",
    "#import opencv\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9fbf4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Vizdoom OpenAI Gym Environment\n",
    "class VizDoomGym(Env): \n",
    "    # Function that is called when we start the env\n",
    "    def __init__(self, render=False): \n",
    "        # Inherit from Env\n",
    "        super().__init__()\n",
    "        # Setup the game \n",
    "        self.game = DoomGame()\n",
    "        self.game.load_config('github/VizDoom/scenarios/basic.cfg')\n",
    "        \n",
    "        # Render frame logic\n",
    "        if render == False: \n",
    "            self.game.set_window_visible(False)\n",
    "        else:\n",
    "            self.game.set_window_visible(True)\n",
    "        \n",
    "        # Start the game \n",
    "        self.game.init()\n",
    "        \n",
    "        # Create the action space and observation space\n",
    "        self.observation_space = Box(low=0, high=255, shape=(100,160,1), dtype=np.uint8) \n",
    "        self.action_space = Discrete(3)\n",
    "        \n",
    "    # This is how we take a step in the environment\n",
    "    def step(self, action):\n",
    "        # Specify action and take step \n",
    "        actions = np.identity(3)\n",
    "        reward = self.game.make_action(actions[action], 4) \n",
    "        \n",
    "        # Get all the other stuff we need to retun \n",
    "        if self.game.get_state(): \n",
    "            state = self.game.get_state().screen_buffer\n",
    "            state = self.grayscale(state)\n",
    "            ammo = self.game.get_state().game_variables[0]\n",
    "            info = ammo\n",
    "        else: \n",
    "            state = np.zeros(self.observation_space.shape)\n",
    "            info = 0 \n",
    "        \n",
    "        info = {\"info\":info}\n",
    "        done = self.game.is_episode_finished()\n",
    "        \n",
    "        return state, reward, done, info \n",
    "    \n",
    "    # Define how to render the game or environment \n",
    "    def render(): \n",
    "        pass\n",
    "    \n",
    "    # What happens when we start a new game \n",
    "    def reset(self): \n",
    "        self.game.new_episode()\n",
    "        state = self.game.get_state().screen_buffer\n",
    "        return self.grayscale(state)\n",
    "    \n",
    "    # Grayscale the game frame and resize it \n",
    "    def grayscale(self, observation):\n",
    "        gray = cv2.cvtColor(np.moveaxis(observation, 0, -1), cv2.COLOR_BGR2GRAY)\n",
    "        resize = cv2.resize(gray, (160,100), interpolation=cv2.INTER_CUBIC)\n",
    "        state = np.reshape(resize, (100,160,1))\n",
    "        return state\n",
    "    \n",
    "    # Call to close down the game\n",
    "    def close(self): \n",
    "        self.game.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ec70b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=VizDoomGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d55fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fdc0729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for a valid env\n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fd44f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9968b2",
   "metadata": {},
   "source": [
    "# Setup callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe306a6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch in c:\\users\\andre\\anaconda3\\lib\\site-packages (1.12.1)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.13.1%2Bcu113-cp38-cp38-win_amd64.whl (4.7 MB)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.12.1%2Bcu113-cp38-cp38-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\andre\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: requests in c:\\users\\andre\\anaconda3\\lib\\site-packages (from torchvision) (2.25.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\andre\\anaconda3\\lib\\site-packages (from torchvision) (1.20.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests->torchvision) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests->torchvision) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.10)\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "Successfully installed torchaudio-0.12.1+cu113 torchvision-0.13.1+cu113\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70dd44af",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\andre\\anaconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: torch>=1.11 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.12.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\andre\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.20.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\andre\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.2.4)\n",
      "Requirement already satisfied: gym==0.21 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.21.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\andre\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.3.4)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\andre\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (1.6.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (2.8.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\andre\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (5.8.0)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: protobuf~=3.19.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (3.19.4)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\andre\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (4.6.0.66)\n",
      "Requirement already satisfied: ale-py==0.7.4 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (0.7.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\andre\\anaconda3\\lib\\site-packages (from stable-baselines3[extra]) (8.2.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\andre\\anaconda3\\lib\\site-packages (from ale-py==0.7.4->stable-baselines3[extra]) (5.7.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from ale-py==0.7.4->stable-baselines3[extra]) (4.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\andre\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (4.59.0)\n",
      "Requirement already satisfied: click in c:\\users\\andre\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (7.1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\andre\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.25.1)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\andre\\anaconda3\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.10.0->ale-py==0.7.4->stable-baselines3[extra]) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (52.0.0.post20210125)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.3.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.36.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.6.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.44.0)\n",
      "Requirement already satisfied: six in c:\\users\\andre\\anaconda3\\lib\\site-packages (from absl-py>=0.4->tensorboard>=2.2.0->stable-baselines3[extra]) (1.15.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\andre\\anaconda3\\lib\\site-packages (from torch>=1.11->stable-baselines3[extra]) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2021.1)\n"
     ]
    }
   ],
   "source": [
    "#so we can use ppo \n",
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61d81ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os for file nav\n",
    "import os \n",
    "# Import callback class from sb3\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e97b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8105e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/train_basic'\n",
    "LOG_DIR = './logs/log_basic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5be7aee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback= TrainAndLoggingCallback(check_freq=10000,save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead4af8d",
   "metadata": {},
   "source": [
    "# Train with PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6117060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ppo\n",
    "from stable_baselines3 import PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16fb8f3c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\andre\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (0.25.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\andre\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d4f2e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#non render env\n",
    "env= VizDoomGym()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86714955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "#cnnpolicy for img\n",
    "#verbose give some info\n",
    "model= PPO('CnnPolicy',env,tensorboard_log=LOG_DIR,verbose=1,learning_rate=0.0001,n_steps=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c0743000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/log_basic\\PPO_9\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | -71.2    |\n",
      "| time/              |          |\n",
      "|    fps             | 25       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 80       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 26.2        |\n",
      "|    ep_rew_mean          | -45.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010885042 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.000267    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.000309   |\n",
      "|    value_loss           | 2.43e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.8        |\n",
      "|    ep_rew_mean          | -72.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 412         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011126598 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00126    |\n",
      "|    value_loss           | 3.47e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 25.4        |\n",
      "|    ep_rew_mean          | -43.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 13          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 602         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009289934 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.6e+03     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00124    |\n",
      "|    value_loss           | 3.18e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 21.4       |\n",
      "|    ep_rew_mean          | -14.3      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 793        |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01817584 |\n",
      "|    clip_fraction        | 0.408      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0.43       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.63e+03   |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | 0.014      |\n",
      "|    value_loss           | 3.79e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 22.5        |\n",
      "|    ep_rew_mean          | -25.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 984         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018133413 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.01e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | 0.00261     |\n",
      "|    value_loss           | 4.12e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.2        |\n",
      "|    ep_rew_mean          | -5.39       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 1164        |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021852618 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.59e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | 0.00963     |\n",
      "|    value_loss           | 2.89e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 17.3        |\n",
      "|    ep_rew_mean          | 12.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 1332        |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012976093 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.974      |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.5e+03     |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | 0.00257     |\n",
      "|    value_loss           | 3.22e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 20.3        |\n",
      "|    ep_rew_mean          | -5.23       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1498        |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028827308 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.939      |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.77e+03    |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | 0.0123      |\n",
      "|    value_loss           | 3.86e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 14.3       |\n",
      "|    ep_rew_mean          | 28.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 1679       |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01739862 |\n",
      "|    clip_fraction        | 0.313      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.945     |\n",
      "|    explained_variance   | 0.538      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.78e+03   |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | 0.00566    |\n",
      "|    value_loss           | 3.64e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 19.7      |\n",
      "|    ep_rew_mean          | -5.95     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 12        |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 1844      |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0298495 |\n",
      "|    clip_fraction        | 0.383     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.866    |\n",
      "|    explained_variance   | 0.572     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.27e+03  |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | 0.0347    |\n",
      "|    value_loss           | 2.53e+03  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 14.8       |\n",
      "|    ep_rew_mean          | 25.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 2012       |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01827214 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.801     |\n",
      "|    explained_variance   | 0.544      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.87e+03   |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | 0.00468    |\n",
      "|    value_loss           | 3.57e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12          |\n",
      "|    ep_rew_mean          | 40.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 2181        |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020830244 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.754      |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    value_loss           | 2.92e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.1        |\n",
      "|    ep_rew_mean          | 41.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 2349        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017462522 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.698      |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 937         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -1.01e-05   |\n",
      "|    value_loss           | 1.64e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 9.9         |\n",
      "|    ep_rew_mean          | 55.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 2517        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026101168 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.641      |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 779         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | 0.0174      |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 6.78        |\n",
      "|    ep_rew_mean          | 72.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 2691        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.064672604 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.706      |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 724         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | 0.0158      |\n",
      "|    value_loss           | 1.65e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 6.51      |\n",
      "|    ep_rew_mean          | 71.9      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 12        |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 2868      |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1646047 |\n",
      "|    clip_fraction        | 0.52      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.683    |\n",
      "|    explained_variance   | 0.635     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 291       |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | 0.0879    |\n",
      "|    value_loss           | 602       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 6.68       |\n",
      "|    ep_rew_mean          | 71.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 3047       |\n",
      "|    total_timesteps      | 36864      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06572437 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.491     |\n",
      "|    explained_variance   | 0.545      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 204        |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | 0.0265     |\n",
      "|    value_loss           | 569        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.99       |\n",
      "|    ep_rew_mean          | 76         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 3225       |\n",
      "|    total_timesteps      | 38912      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10473559 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.431     |\n",
      "|    explained_variance   | 0.632      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 154        |\n",
      "|    n_updates            | 180        |\n",
      "|    policy_gradient_loss | 0.012      |\n",
      "|    value_loss           | 452        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.98       |\n",
      "|    ep_rew_mean          | 81         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 12         |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 3404       |\n",
      "|    total_timesteps      | 40960      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06299419 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.328     |\n",
      "|    explained_variance   | 0.468      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 133        |\n",
      "|    n_updates            | 190        |\n",
      "|    policy_gradient_loss | 0.00658    |\n",
      "|    value_loss           | 282        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-3000ab6e0ff5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    308\u001b[0m     ) -> \"PPO\":\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         return super().learn(\n\u001b[0m\u001b[0;32m    311\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m             \u001b[0mcontinue_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    173\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             \u001b[0mnew_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \"\"\"\n\u001b[0;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_transpose.py\u001b[0m in \u001b[0;36mstep_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mVecEnvStepReturn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mobservations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvenv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;31m# Transpose the terminal observations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[1;31m# save final observation where user can get it, then reset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuf_infos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"terminal_observation\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m                 \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_obs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_obs_from_buf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuf_rews\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuf_dones\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuf_infos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\monitor.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Expected you to pass keyword argument {key} into reset\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_reset_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mGymStepReturn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-65745addfda9>\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# What happens when we start a new game\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_episode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscreen_buffer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrayscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000,callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e843b",
   "metadata": {},
   "source": [
    "#### PPO3 is 2046 n_steps learn_rate is .0001 best_model_60000\n",
    "#### PPO8 is 2048 n_steps(im stupid) learn rate .001 best model 12k\n",
    "#### PPO9  is 2048  \"\" learn rate .0001 best model 16k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8049843b",
   "metadata": {},
   "source": [
    "approx_kl:ppo look the old agent for the new one,this measure how much those 2 agents are different,if we got a spike in this value we have huge divergence, the next value \"clip\" its how ppo solve this problem also we can set hyperparamtre like clip_range & gae_lambda if we have to much spike.\n",
    "explained_variance: we want this to be positive cus it tells how the critic module is predicting\n",
    "policy_gradient_loss: if goes to 0 the model isnt learning and is doing the same thing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d69479",
   "metadata": {},
   "source": [
    "tensorboard --logdir=. shell comand from the folder where the training data is saved for looking the graphs\n",
    "\n",
    "data whe found:\n",
    "###### ep_lenght_mean=how much we live\n",
    "##### ep_reward_mean=reward\n",
    "##### experience_variance= we want to improve this value\n",
    "##### value_loss= we want near 0\n",
    "##### policy_gradient_lost=if drop to 0 to fast the model isnt learning,\n",
    "##### approx_kl= same as policy_grad if near 0 the agent is takin same action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72e52f6",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acef6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import eval policy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96b4f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltest= PPO.load('./train/train_basic/best_model_160000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11338f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=VizDoomGym(render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd79b1fb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:65: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#mean reward for 10 games \n",
    "mean_rew, _ = evaluate_policy(modeltest,env,n_eval_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b3aeb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward for episode 0 is 13.0\n",
      "Total Reward for episode 1 is 95.0\n",
      "Total Reward for episode 2 is 60.0\n",
      "Total Reward for episode 3 is 95.0\n",
      "Total Reward for episode 4 is -3.0\n"
     ]
    }
   ],
   "source": [
    "for episode in range(5): \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = modeltest.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        time.sleep(0.20)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "115c788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba5f1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
